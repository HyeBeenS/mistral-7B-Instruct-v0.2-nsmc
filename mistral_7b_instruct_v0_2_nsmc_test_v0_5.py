# -*- coding: utf-8 -*-
"""mistral-7B-instruct-v0.2-nsmc-test-v0.5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iHmjvcdzeGQ6N41j9izs0PXHFlhMgwK3

- food-order-understanding-small-3200.json (학습)
- food-order-understanding-small-800.json (검증)

- 로깅을 위한 wandb

mistral model
https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2

# 세팅
"""

pip install transformers peft accelerate optimum bitsandbytes trl wandb

import os
from dataclasses import dataclass, field
from typing import Optional
import re

import torch
import tyro
from accelerate import Accelerator
from datasets import load_dataset, Dataset
from peft import AutoPeftModelForCausalLM, LoraConfig
from tqdm import tqdm
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments,
)

from trl import SFTTrainer

from trl.trainer import ConstantLengthDataset
from transformers import pipeline, TextStreamer

import pickle
import pandas as pd
from sklearn.metrics import f1_score, classification_report, confusion_matrix

from huggingface_hub import notebook_login

notebook_login()

"""드라이브 마운트 후 파일 업로드
- food-order-understanding-small-3200.json
- food-order-understanding-small-800.json
"""

from google.colab import drive
drive.mount('/gdrive')

"""# 평가

- 1000개에 대해 테스트하여 accuracy 측정 추가 필요
- https://huggingface.co/docs/transformers/main/ko/training
"""

base_model_save_path = '/gdrive/MyDrive/undergraduateReasearcher/mistral-7B-instruct-v0.2-nsmc-eval-dict/base-model-eval-dict-pickle-v0.1'

# 파일에서 base_model의 eval_dic 불러오기
with open(base_model_save_path, 'rb') as f:
    loaded_eval_dic_for_base_model = pickle.load(f)

# 불러온 딕셔너리 사용
print(loaded_eval_dic_for_base_model)

trained_model_save_path = '/gdrive/MyDrive/undergraduateReasearcher/mistral-7B-instruct-v0.2-nsmc-eval-dict/trained-model-eval-dict-pickle-v0.2'

# 파일에서 trained_model의 eval_dic 불러오기
with open(trained_model_save_path, 'rb') as f:
    loaded_eval_dic_for_trained_model = pickle.load(f)

# 불러온 딕셔너리 사용
print(loaded_eval_dic_for_trained_model)

for idx, val in loaded_eval_dic_for_trained_model.items():
  print(idx, val[0]['label'], val[1])
  break

pred_data = [{'idx':idx, 'label': val[0]['label'], 'pred':1 if val[1] == '"긍정" ' else 0} for idx, val in loaded_eval_dic_for_trained_model.items()]

df = pd.DataFrame.from_records(pred_data)

from sklearn.metrics import f1_score, classification_report, confusion_matrix
print(f1_score(df.label, df.pred))

"""'"긍정" ', '"부정" ' 외에 다르게 생성한 것이 있는지 확인 추가 작업 필요(eval_dic)"""

print(classification_report(df.label, df.pred))

print(confusion_matrix(df.label, df.pred, normalize='true'))   # 옵션 조사

eval_dic_labels = []
eval_dic_sentiments = []
for idx, val in loaded_eval_dic_for_trained_model.items():
  eval_dic_labels = val[0]['label']
  eval_dic_sentiments =
  print(idx, val[0]['label'], 1 if val[1] == '"긍정" ' else 0)
  break

eval_dic_labels = [val[0]['label'] for idx, val in loaded_eval_dic_for_trained_model.items()]
eval_dic_sentiments = [1 if val[1] == '"긍정" ' else 0 for sentiment in eval_dic_base_sentiments]

print(loaded_eval_dic_for_trained_model[0])
print(loaded_eval_dic_for_trained_model[0][0])
print(loaded_eval_dic_for_trained_model[0][1])

from datasets import load_metric

metric = load_metric("glue", "mrpc")

"""# 9. 모델 업로드"""

trained_model.save_pretrained("/gdrive/MyDrive/undergraduateReasearcher/mistral-instruct-v0.2-results-nsmc-consecutive")

tokenizer.save_pretrained("/gdrive/MyDrive/undergraduateReasearcher/mistral-instruct-v0.2-results-nsmc-consecutive")

trained_model.push_to_hub("ssalbab/Mistral-7B-Instruct-v0.2-nsmc-fine-tuning-v0.2", use_auth_token=True)

tokenizer.push_to_hub("ssalbab/Mistral-7B-Instruct-v0.2-nsmc-fine-tuning-v0.2", use_auth_token=True)